import { VoiceResponse } from '@/types'; // Ensure this type is defined, e.g.:
                                        // export interface VoiceResponse {
                                        //   text: string;
                                        //   audio_url: string;
                                        // }

// API endpoint for voice processing - REMINDER: ngrok URLs are temporary.
const API_ENDPOINT = '{update your endpoint}/api/analyze-audio';

/**
 * Sends audio data to the backend API for processing.
 * The backend now uses ElevenLabs for Text-to-Speech.
 * @param audioDataUrl The audio data as a full data URL (e.g., "data:audio/webm;base64,XXXX...").
 * @returns A Promise resolving to a VoiceResponse object containing the transcribed text
 * and a data URL to the spoken response audio (generated server-side by ElevenLabs).
 */
export const sendAudioToAPI = async (audioDataUrl: string): Promise<VoiceResponse> => {
  try {
    const response = await fetch(API_ENDPOINT, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        audio: audioDataUrl
      }),
    });

    if (!response.ok) {
      let errorMessage = 'Failed to process audio via API';
      try {
        const errorData = await response.json();
        if (errorData && errorData.error) {
          errorMessage = errorData.error;
        } else if (response.statusText) {
          errorMessage = `API Error: ${response.status} ${response.statusText}`;
        }
      } catch (e) {
        // If response is not JSON or another error occurs during error parsing
        errorMessage = `API Error: ${response.status} ${response.statusText || 'Unknown error during error parsing'}`;
      }
      throw new Error(errorMessage);
    }

    const data = await response.json();
    return {
      text: data.text,
      audio_url: data.audio_url // This audio_url is generated by the server using ElevenLabs
    };
  } catch (error) {
    console.error('API request (sendAudioToAPI) failed:', error);
    throw error; // Re-throw for the caller to handle
  }
};

// --- Client-side ElevenLabs TTS Utility ---
// WARNING: Exposing API keys directly in client-side code is a MAJOR SECURITY RISK.
// This key can be discovered by anyone inspecting your website/application, leading to potential misuse.
// For production or shared applications, proxy these requests through your own backend server
// where the API key can be kept secret.
// This function is provided as you've hardcoded keys previously, but use with extreme caution.

const ELEVENLABS_API_KEY = 'sk_7f079ad3bf82aea8b767e8f4fa8d24aee4999c0da933a4e2'; // Your hardcoded key

// You MUST provide a valid Voice ID.
// Find your desired Voice IDs in your ElevenLabs dashboard (e.g., under 'Voice Lab').
// Using "Rachel" as an example default. CHANGE THIS AS NEEDED.
const ELEVENLABS_VOICE_ID = '21m00Tcm4TlvDq8ikWAM';

/**
 * Converts text to speech using ElevenLabs API directly from the client-side.
 * NOTE: The primary application flow now uses server-side TTS via `sendAudioToAPI`.
 * This function might be used for other client-side specific TTS needs if absolutely required,
 * but be mindful of the API key exposure.
 * @param text The text to convert to speech.
 * @returns A Promise resolving to a data URL (base64 encoded audio/mpeg) for the generated speech.
 */
export const getTTSFromElevenLabs = async (text: string): Promise<string> => {
  if (!ELEVENLABS_VOICE_ID) {
    const errorMessage = 'Client-side ElevenLabs Voice ID is not set. Please configure it.';
    console.error(errorMessage);
    throw new Error(errorMessage);
  }
  if (!ELEVENLABS_API_KEY.startsWith('sk_')) { // Basic check for key format
    const errorMessage = 'Client-side ElevenLabs API Key appears invalid or is not set.';
    console.warn(errorMessage); // Warn but allow attempt if user insists on a non-standard key
  }

  try {
    const response = await fetch(
      `https://api.elevenlabs.io/v1/text-to-speech/${ELEVENLABS_VOICE_ID}`,
      {
        method: 'POST',
        headers: {
          'xi-api-key': ELEVENLABS_API_KEY,
          'Content-Type': 'application/json',
          'Accept': 'audio/mpeg',
        },
        body: JSON.stringify({
          text,
          model_id: 'eleven_monolingual_v1', // Or your preferred model, e.g., 'eleven_multilingual_v2'
          voice_settings: {
            stability: 0.5,
            similarity_boost: 0.5,
          },
        }),
      }
    );

    if (!response.ok) {
      const errorBody = await response.text(); // Get more details from ElevenLabs API error
      throw new Error(`Failed to get TTS from ElevenLabs (client-side): ${response.status} ${response.statusText}. Details: ${errorBody}`);
    }

    const audioBlob = await response.blob();
    const base64 = await new Promise<string>((resolve, reject) => {
      const reader = new FileReader();
      reader.onloadend = () => {
        const dataUrl = reader.result as string;
        // Remove the "data:audio/mpeg;base64," prefix to get just the base64 data
        resolve(dataUrl.split(',')[1]);
      };
      reader.onerror = reject;
      reader.readAsDataURL(audioBlob);
    });

    // Return the full data URL, including the prefix
    return `data:audio/mpeg;base64,${base64}`;
  } catch (error) {
    console.error('Client-side ElevenLabs TTS request (getTTSFromElevenLabs) failed:', error);
    throw error; // Re-throw for the caller to handle
  }
};